## These Projects Are Currently Under Development
Thank you for your interest in my work! I currently have three main projects in development currently.

# Gesture Controller
This is a machine learning project that is currently 80% completed. The main purpose is to enable users who might have trouble using a mouse to navigate their computers with ease. Using hand tracking modules from MediaPipe as well as gesture recognition models I trained, users are able to use a variety of recognized gestures to open up specific applications, adjust computer volume, or switch between tabs easily.

# AWS S3 + Elasticsearch Front-end
This project was completed during my internship with Praxis Engineering. I have not yet compiled code samples and images for display although it will occur soon. The developed webpage utilizes API endpoints set in Amazon Web Services Lambda to run python programs when actions are taken (i.e. clicking a button). These python programs interface with AWS S3, allowing me to pull data stored in S3 buckets as well as interface with Elasticsearch, a NoSQL database. The user is able to upload data to the databases through the webpage as well as list all current data. They can also search for data by terms through the use of a fuzzysearch in the Elasticsearch API.

# 7-DOF Robotic Arm
I am currently working as a part-time intern with NIST's Intelligent Systems Division. My job entails developing and implementing machine learning algorithms and integrating 3D sensors and 360° cameras on a mobile emergency response robot to allow it to autonomously open doors. Some of my specific tasks involve:
- Using ROS to control a mobile robot with a 7-DOF manipulator
- Integrating an Intel RealSense sensor and a Theta 360° camera in ROS/Unity (in Windows) on the robot
- Integrating an Oculus Rift VR headset with ROS/Unity to display an augmented reality view overlayed with the RealSense data
